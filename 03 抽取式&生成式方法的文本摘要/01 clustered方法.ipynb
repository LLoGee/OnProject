{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12926c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a5d6d8",
   "metadata": {},
   "source": [
    "# 1. data loading section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "454ead3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = 5000\n",
    "\n",
    "def load_data(data_dir):\n",
    "    global nums\n",
    "    with open(data_dir, \"r\", encoding='utf-8') as fp:\n",
    "        data = [line.strip().split(\"\\t\") for line in fp.readlines() if len(line.strip().split(\"\\t\"))==1]\n",
    "    data = pd.DataFrame(data[:nums], columns=None)\n",
    "    return data\n",
    "    \n",
    "texts_dir = \"./Data/texts.txt\"\n",
    "summaries_dir = \"./Data/summaries.txt\"\n",
    "\n",
    "texts = load_data(texts_dir)\n",
    "summaries = load_data(summaries_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f183f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ensure that our data is not too long, we choose a source text string of 6000 characters or less as our data set, \n",
    "# and the number of characters must be greater than 30\n",
    "str_indexes = []\n",
    "for i in range(len(texts)):\n",
    "    if type(texts[0][i]) == type(\"str\") and len(texts[0][i])<6000 and len(texts[0][i])>30:\n",
    "        str_indexes.append(i)\n",
    "texts = [texts[0][i] for i in str_indexes]\n",
    "summaries = [summaries[0][i] for i in str_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1da15adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1457"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally we select 1457 data as our training set\n",
    "lg = len(texts)\n",
    "lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a30d13ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train nums:  1093\n",
      "test nums:  364\n"
     ]
    }
   ],
   "source": [
    "# Slice and dice the dataset into a training set and a test set\n",
    "split = 0.25\n",
    "def split_data(texts, summaries):\n",
    "    global split, lg\n",
    "    # Randomly get 2000*0.25 indexes within 2000 using the random module\n",
    "    test_index = random.sample(range(lg),int(lg*split))\n",
    "\n",
    "    train_texts = [texts[i] for i in range(lg) if i not in test_index]\n",
    "    test_texts = [texts[i] for i in range(lg) if i in test_index]\n",
    "    train_summaries = [summaries[i] for i in range(lg) if i not in test_index]\n",
    "    test_summaries = [summaries[i] for i in range(lg) if i in test_index]\n",
    "    \n",
    "    return train_texts, test_texts, train_summaries, test_summaries\n",
    "\n",
    "train_texts, test_texts, train_summaries, test_summaries = split_data(texts, summaries)\n",
    "# View the length of the training and test sets\n",
    "print(\"train nums: \", len(train_texts))\n",
    "print(\"test nums: \", len(test_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dae154b",
   "metadata": {},
   "source": [
    "# 2. data cleaning section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6bb01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the source text where ||||| is not required\n",
    "# You can see that for the summary text, the \"- \" at the beginning first is not required\n",
    "\n",
    "def clear(texts, summaries):\n",
    "    # Clear the extra symbols at the beginning\n",
    "    for i in range(len(summaries)):\n",
    "        summaries[i] = summaries[i][2:]\n",
    "    \n",
    "    for j in range(len(texts)):\n",
    "        texts[j] = texts[j].replace(\"|\", \"\")\n",
    "    \n",
    "    return texts, summaries\n",
    "train_texts, train_summaries =  clear(train_texts, train_summaries)\n",
    "test_texts, test_summaries =  clear(test_texts, test_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adcdc706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence slicing of text\n",
    "from nltk.tokenize import sent_tokenize\n",
    "def sentence_split(text_data):\n",
    "    All_text = []\n",
    "    for i in range(len(text_data)):\n",
    "        sentence_lis = sent_tokenize(text_data[i])\n",
    "        All_text.append(sentence_lis)\n",
    "        \n",
    "    return All_text\n",
    "\n",
    "splited_train_texts = sentence_split(train_texts)\n",
    "splited_train_summaries = sentence_split(train_summaries)\n",
    "splited_test_texts = sentence_split(test_texts)\n",
    "splited_test_summaries = sentence_split(test_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf14fdd",
   "metadata": {},
   "source": [
    "## Atention ------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8a69fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that here the processed training and test sets are saved as csv files\n",
    "# for use by other model methods\n",
    "train_s = {\"text\":train_texts, \"summary\":train_summaries}\n",
    "test_s = {\"text\":test_texts, \"summary\":test_summaries}\n",
    "train_df = pd.DataFrame(train_s)\n",
    "test_df = pd.DataFrame(test_s)\n",
    "train_df.to_csv('./Data/train_text_summary.csv', index=False)\n",
    "test_df.to_csv('./Data/test_text_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003b390b",
   "metadata": {},
   "source": [
    "## Atention ------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c05374c",
   "metadata": {},
   "source": [
    "# 3. data vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "748e00d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import tensorflow_text\n",
    "from transformers import AdamWeightDecay\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "from sklearn.metrics import pairwise_distances_argmin_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85e9418b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: GeForce GTX 1650 Ti, compute capability 7.5\n",
      "Compute dtype: float16\n",
      "Variable dtype: float32\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# GPU uses mixed precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "print('Compute dtype: %s' % policy.compute_dtype)\n",
    "print('Variable dtype: %s' % policy.variable_dtype)\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "print(gpus)\n",
    "# Whether to limit all GPU memory growth True to limit\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(device=gpu, enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5587883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the downloaded pre-trained model sentence encoder\n",
    "encoder = hub.load(\"./embedding_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f137aa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the sentence\n",
    "def embedding(splited_texts):\n",
    "    data = []\n",
    "    for i in range(len(splited_texts)):\n",
    "        embedding_sentences = encoder(splited_texts[i])\n",
    "        data.append(embedding_sentences)\n",
    "    return data\n",
    "    \n",
    "train_texts_data = embedding(splited_train_texts)\n",
    "# train_summaries_data = embedding(splited_train_summaries)\n",
    "test_texts_data = embedding(splited_test_texts)\n",
    "# test_summaries_data = embedding(splited_test_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85d2de7",
   "metadata": {},
   "source": [
    "# 4. perform clustering to obtain summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f95b9455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each cluster after clustering can be considered as a set of semantically similar sentences, \n",
    "# and we only need one of them to represent\n",
    "# This sentence is selected by considering the sentence closest to the cluster center, \n",
    "# and then sorting the candidate sentences of each cluster to form the final text summary\n",
    "\n",
    "# And we have the following two requirements\n",
    "# The order of the candidate sentences in the summary is determined by the position of the sentences in the original email in their corresponding clusters.\n",
    "# For example, if most of the sentences located in their clusters appear at the beginning of the email, \n",
    "# the candidate sentences are selected as the first sentences in the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db74a4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def cluster_summarization(text_data,slpited_texts):\n",
    "    Summaries = []\n",
    "    for i in range(len(text_data)):\n",
    "        # of clustering centers is 0.4 of the number of text sentences, then initialize a clustering center\n",
    "        n_clusters = int(np.ceil((len(text_data[i])*0.4)))\n",
    "        kmeans = KMeans(n_clusters=n_clusters).fit(text_data[i])\n",
    "        \n",
    "        avg = []\n",
    "        for j in range(n_clusters):\n",
    "            idx = np.where(kmeans.labels_ == j)[0]\n",
    "            avg.append(np.mean(idx))\n",
    "        # Get a list of the closest sentence indexes for each each category to the cluster center\n",
    "        closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, text_data[i])\n",
    "        # Get the ordering of the sentences\n",
    "        ordering = sorted(range(n_clusters), key=lambda k: avg[k])\n",
    "        # Final splicing of selected sentences into a summary\n",
    "        summary = ' '.join([slpited_texts[i][closest[idx]] for idx in ordering])\n",
    "        Summaries.append(summary)\n",
    "\n",
    "    return Summaries\n",
    "\n",
    "predict_summaries = cluster_summarization(train_texts_data, splited_train_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d8ca89",
   "metadata": {},
   "source": [
    "# 6. ROUGE and BLEU score in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45ce4fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get the prediction summary for the test set, select 100 data\n",
    "predict_summaries_test = cluster_summarization(test_texts_data[:100], splited_test_texts[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54878b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 score:  0.3516382709092894\n",
      "Rouge-2 score:  0.1330131760557666\n",
      "BLEU score:  0.4015825086167629\n"
     ]
    }
   ],
   "source": [
    "# Import rouge Blue and calculate score, get Rouge-1 and Rouge-2 scores for the first 100 test data\n",
    "from rouge import Rouge\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def compute_score(predict_summaries_test, test_summaries):\n",
    "    rouge = Rouge()\n",
    "    Rouge_1 = []\n",
    "    Rouge_2 = []\n",
    "    B = []\n",
    "\n",
    "    for i in range(len(test_texts[:100])):\n",
    "        score = rouge.get_scores(predict_summaries_test[i], test_summaries[:100][i])\n",
    "        score_B = sentence_bleu([test_summaries[:100][i]], predict_summaries_test[i])\n",
    "        B.append(score_B)\n",
    "        Rouge_1.append(score[0][\"rouge-1\"][\"r\"])\n",
    "        Rouge_2.append(score[0][\"rouge-2\"][\"r\"])\n",
    "\n",
    "    print(\"Rouge-1 score: \", sum(Rouge_1)/len(Rouge_1))\n",
    "    print(\"Rouge-2 score: \", sum(Rouge_2)/len(Rouge_2))\n",
    "    print(\"BLEU score: \", sum(B)/len(B))\n",
    "    \n",
    "compute_score(predict_summaries_test, test_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4403f15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# store the predict data as csv \n",
    "DF = {\"reference\":test_summaries[:100], \"Clustered_predict\":predict_summaries_test}\n",
    "df = pd.DataFrame(DF)\n",
    "df.to_csv('./Data/Clustered_predict_summaries.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71dedce3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"But the couple's lawsuit may provide too much of a peek behind the reality television curtain. NEWLINE_CHAR NEWLINE_CHAR In a statement to TODAY, the couple’s attorney said the company’s incentive was “to make decisions that favor the television show but not the homeowners.” NEWLINE_CHAR NEWLINE_CHAR RELATED: 'Fixer Upper' Joanna Gaines shares her spring cleaning checklist NEWLINE_CHAR NEWLINE_CHAR The “Love It or List It” production company disputes the allegation. NEWLINE_CHAR NEWLINE_CHAR For the episode, which aired in April 2015, Murphy and Sullivan were asked to deposit $140,000 into a fund with the production company, who would later use that money to pay Fitz and other subcontractors. NEWLINE_CHAR NEWLINE_CHAR According to the suit, the actual work done on the house was “disastrous,” leaving the home “irreparably damaged.” Duct work was left open, leading to vermin entering the house, and the couple complains of “low-grade industrial carpeting, unpainted surfaces, and windows painted shut.” NEWLINE_CHAR NEWLINE_CHAR As the News & Observer summarizes, “Big Coat’s purported agreement,” the lawsuit contends, ‘admits that it is in the business of television production, not construction. The Raleigh News & Observer says that Deena Murphy and Timothy Sullivan agreed to participate in the hit HGTV series under the guise that they were considering a move to a rental property with their teenage foster children. The problem, according to the suit against Big Coat TV and Aaron Fitz Construction, was that the show’s principals—designer Hilary Farr, real estate agent David Visentin, and contractor Eric Eremita—are “actors or television personalities playing a role for the camera,” not people who “played more than a casual role in the actual renovation process.” While this shouldn’t come as a surprise to anyone who’s ever suffered through Farr and Visentin’s bullshit “no, you are” banter, it’s still mildly disheartening to hear. Over the course of the renovations, only $85,780.50 was disbursed to Fitz, leaving the couple wondering where the rest of their money went. The suit also questions how Big Coat can operate as a general contractor, a role it’s not licensed for. They also say any work done on the show was work that they’d previously made plans for with another company, Werx-Design Build. ...\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_summaries_test[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e215ca96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When Deena Murphy and Timothy Sullivan wanted to renovate their Raleigh, NC, rental property, they didn\\'t want a DIY project, so they did what they thought was the next best thing: signed up to have an HGTV show do it for them. But per a lawsuit the couple has now filed against Big Coat, the production company behind Love It or List It, as well as the local contractor who overhauled the home, they were left with \"disastrous work,\" including holes in the floor and windows painted shut, the Charlotte Observer reports. The suit also alleges the \"reality-TV\" program is \"scripted, with \\'roles\\' and reactions assigned to the various performers and participants, including the homeowners.\" And the show\\'s hosts, designer Hilary Farr and real estate agent David Visentin, and its resident general contractor? \"Actors or television personalities … [who don\\'t play] more than a casual role in the actual renovation process.\" Per their contract with Big Coat, the couple deposited $140,000 that would be used to pay Aaron Fitz Construction and its subcontractors. About $85,000 was distributed to Aaron Fitz during the overhaul, even though Murphy and Sullivan say they expressed concerns about mediocre reviews seen on Angie\\'s List. The rest of the money got pumped into producing the show, the couple claims, reports Today.com. They say the show is \"even more of a scam than it generally seems,\" as the AV Club frames it. \"The homeowners\\' funds essentially pay the cost of creating a stage set for this television series,\" the suit says. A statement from Big Coat\\'s CEO says the company will \"vigorously defend what we consider to be false allegations.\" (This DIY project took six months to make and much less time to eat.)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_summaries[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc36ffb",
   "metadata": {},
   "source": [
    "# 7. Quick inference Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "097193ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import tensorflow_text\n",
    "from transformers import AdamWeightDecay\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "def sentence_split(text_data):\n",
    "    All_text = []\n",
    "    for i in range(len(text_data)):\n",
    "        sentence_lis = sent_tokenize(text_data[i])\n",
    "        All_text.append(sentence_lis)\n",
    "encoder = hub.load(\"./embedding_model\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def cluster_summarization(text_data,slpited_texts):\n",
    "    Summaries = []\n",
    "    for i in range(len(text_data)):\n",
    "        n_clusters = int(np.ceil((len(text_data[i])*0.4)))\n",
    "        kmeans = KMeans(n_clusters=n_clusters).fit(text_data[i])\n",
    "        \n",
    "        avg = []\n",
    "        for j in range(n_clusters):\n",
    "            idx = np.where(kmeans.labels_ == j)[0]\n",
    "            avg.append(np.mean(idx))\n",
    "        closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, text_data[i])\n",
    "        ordering = sorted(range(n_clusters), key=lambda k: avg[k])\n",
    "        summary = ' '.join([slpited_texts[i][closest[idx]] for idx in ordering])\n",
    "        Summaries.append(summary)\n",
    "\n",
    "    return Summaries\n",
    "\n",
    "def out_summary(text):\n",
    "    T = []\n",
    "    S = []\n",
    "    splited_text = sent_tokenize(text)\n",
    "    text_data = encoder(splited_text)\n",
    "    T.append(text_data)\n",
    "    S.append(splited_text)\n",
    "\n",
    "    print(cluster_summarization(T, S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec18f5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "        For the second time during his papacy, Pope Francis has announced a new group of bishops and archbishops set to become cardinals -- and they come from all over the world.\n",
    "        Pope Francis said Sunday that he would hold a meeting of cardinals on February 14 \"during which I will name 15 new Cardinals who, coming from 13 countries from every continent, manifest the indissoluble links between the Church of Rome and the particular Churches present in the world,\" according to Vatican Radio.\n",
    "        New cardinals are always important because they set the tone in the church and also elect the next pope, CNN Senior Vatican Analyst John L. Allen said. They are sometimes referred to as the princes of the Catholic Church.\n",
    "        The new cardinals come from countries such as Ethiopia, New Zealand and Myanmar.\n",
    "        \"This is a pope who very much wants to reach out to people on the margins, and you clearly see that in this set,\" Allen said. \"You're talking about cardinals from typically overlooked places, like Cape Verde, the Pacific island of Tonga, Panama, Thailand, Uruguay.\"\n",
    "        But for the second time since Francis' election, no Americans made the list.\n",
    "        \"Francis' pattern is very clear: He wants to go to the geographical peripheries rather than places that are already top-heavy with cardinals,\" Allen said.\n",
    "        Christopher Bellitto, a professor of church history at Kean University in New Jersey, noted that Francis announced his new slate of cardinals on the Catholic Feast of the Epiphany, which commemorates the visit of the Magi to Jesus' birthplace in Bethlehem.\n",
    "        \"On feast of three wise men from far away, the Pope's choices for cardinal say that every local church deserves a place at the big table.\"\n",
    "        In other words, Francis wants a more decentralized church and wants to hear reform ideas from small communities that sit far from Catholicism's power centers, Bellitto said.\n",
    "        That doesn't mean Francis is the first pontiff to appoint cardinals from the developing world, though. Beginning in the 1920s, an increasing number of Latin American churchmen were named cardinals, and in the 1960s, St. John XXIII, whom Francis canonized last year, appointed the first cardinals from Japan, the Philippines and Africa.\n",
    "        In addition to the 15 new cardinals Francis named on Sunday, five retired archbishops and bishops will also be honored as cardinals.\n",
    "        Last year, Pope Francis appointed 19 new cardinals, including bishops from Haiti and Burkina Faso.\n",
    "        CNN's Daniel Burke and Christabelle Fombu contributed to this report.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ac33ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''summarize: Us officials are losing confidence that even if they work with Allies to provide Ukraine with heavier and more advanced weapons. the country will not be able to achieve its insistent goal of retaking all the territory seized by Russia in the past four months. CNN reported it on Sunday.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37dd3916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summarize: Us officials are losing confidence that even if they work with Allies to provide Ukraine with heavier and more advanced weapons. the country will not be able to achieve its insistent goal of retaking all the territory seized by Russia in the past four months. CNN reported it on Sunday.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8d00a98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the country will not be able to achieve its insistent goal of retaking all the territory seized by Russia in the past four months. CNN reported it on Sunday.']\n"
     ]
    }
   ],
   "source": [
    "out_summary(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
