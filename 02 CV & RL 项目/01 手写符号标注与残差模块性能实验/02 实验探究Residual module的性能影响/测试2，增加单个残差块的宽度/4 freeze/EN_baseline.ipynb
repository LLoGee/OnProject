{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "998ea97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1d7fb58e9d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets, utils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6acfd5",
   "metadata": {},
   "source": [
    "# Step 1 Build data pipeline and import image dataset (split into training set and test set 5:5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4c43332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "# data_dir is the address where you store your data data, I put it here under relative path\n",
    "data_dir = \"D:/zhuomian/2022_project/data\"\n",
    "split = 0.5\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 40\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26387785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build data pre-processing\n",
    "data_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Resize((56,56)),\n",
    "                                     transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "\n",
    "# Import data into dataset\n",
    "dataset = datasets.ImageFolder(root = data_dir, transform = data_transform)\n",
    "\n",
    "# Now divide the data set into a training set and a test set\n",
    "len_imgs = len(dataset.imgs)\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [int(len_imgs*split), len_imgs-int(len_imgs*split)]) \n",
    "\n",
    "# Final construction of the data pipeline\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size = batch_size,shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,batch_size = batch_size,shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af3282c",
   "metadata": {},
   "source": [
    "# Step 2 Build the model Customized loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f802e20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_model, self).__init__()\n",
    "        # conv2d Parameters nn.Conv2d(in_channels=3, out_channels=32,kernel_size=5,stride=1,padding=\"same\")\n",
    "        # MaxPool2d Parameters nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv0 = nn.Sequential(         \n",
    "            nn.Conv2d(32, 48, 1, 1, padding = \"same\"),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(48, 48, 3, 1, padding = \"same\"),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(48, 32, 1, 1, padding = \"same\"),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(3,  32, 3, 1, padding = \"same\"),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2, 2)    \n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(32, 64, 3, 1, padding = \"same\"),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2, 2)                \n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(         \n",
    "            nn.Conv2d(64, 32, 3, 1, padding = \"same\"),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2, 2)                \n",
    "        )\n",
    "        \n",
    "        # Fully connected layer with 21 output categories\n",
    "        self.fc1 = nn.Sequential(nn.Linear(32 * 7 * 7, 128),nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(nn.Linear(128, 21))\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        identity = x\n",
    "        x = self.conv0(x)\n",
    "        x = identity + x\n",
    "        # Flattening treatment x.view\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        x = self.fc1(x)\n",
    "        output = self.fc2(x)\n",
    "        return output    # return x for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5634690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_model()\n",
    "model.to(device)\n",
    "# Choose whether to print the model or not, here it will not be printed, just comment\n",
    "# print(model)\n",
    "\n",
    "# Select loss function and optimizer\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=learning_rate, betas=(0.9, 0.999),\n",
    "                       eps=1e-07, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ced4cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-1.6705e-01,  9.4571e-02, -1.5766e-01],\n",
      "          [ 2.4070e-02,  1.6082e-02,  6.7943e-02],\n",
      "          [ 9.6198e-02, -1.0258e-01,  1.1997e-02]],\n",
      "\n",
      "         [[-1.1331e-01,  1.3599e-01,  5.6600e-02],\n",
      "          [ 1.6800e-01,  1.5191e-01,  8.6073e-02],\n",
      "          [ 1.2170e-01,  1.8604e-04, -1.4379e-01]],\n",
      "\n",
      "         [[-7.9157e-02, -7.5692e-02, -8.3891e-02],\n",
      "          [-9.7344e-02, -1.8786e-01,  3.5846e-02],\n",
      "          [-1.2211e-01, -1.6781e-01,  5.9788e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8027e-01,  4.1725e-02, -1.1213e-02],\n",
      "          [ 1.0158e-01,  1.5943e-01,  9.4848e-02],\n",
      "          [-1.5441e-01, -1.8395e-02,  8.7878e-02]],\n",
      "\n",
      "         [[-1.5113e-01, -1.8605e-01, -1.7254e-01],\n",
      "          [-1.4346e-01,  8.3391e-02, -5.7112e-02],\n",
      "          [ 7.8017e-02, -1.0249e-01, -4.8690e-02]],\n",
      "\n",
      "         [[-2.8694e-02,  1.8501e-01,  2.5433e-02],\n",
      "          [-1.5733e-01,  1.4851e-01,  1.0754e-02],\n",
      "          [ 1.7372e-01, -1.6462e-03, -1.5580e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1883e-02, -1.0541e-01, -1.3230e-01],\n",
      "          [ 2.0175e-02,  7.2454e-02, -1.0013e-01],\n",
      "          [-5.5031e-02, -7.5045e-02,  1.4523e-01]],\n",
      "\n",
      "         [[ 4.7809e-02, -4.1651e-02, -6.1673e-02],\n",
      "          [-6.9973e-02, -6.6115e-03,  4.6437e-02],\n",
      "          [-7.4286e-02, -8.0058e-02, -1.4234e-01]],\n",
      "\n",
      "         [[ 1.7321e-01, -7.9308e-02,  1.6935e-01],\n",
      "          [-1.9337e-02, -4.4028e-02, -6.8532e-02],\n",
      "          [-2.4396e-03, -8.0634e-03,  4.8906e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.1108e-02,  1.6574e-01,  4.4238e-02],\n",
      "          [-3.1145e-02, -1.3128e-01,  4.7396e-02],\n",
      "          [-1.0358e-02, -2.9034e-02, -1.7562e-01]],\n",
      "\n",
      "         [[ 7.3722e-02,  2.2754e-02,  1.1688e-01],\n",
      "          [-1.0800e-01,  1.1618e-01,  1.4748e-01],\n",
      "          [ 4.3630e-02,  1.4496e-01, -1.8415e-01]],\n",
      "\n",
      "         [[ 1.2500e-01, -6.0521e-02,  6.7740e-02],\n",
      "          [ 1.4066e-01,  2.5816e-02, -3.2053e-03],\n",
      "          [ 8.4646e-02,  1.8478e-01, -1.3740e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7933e-01,  3.0414e-02,  1.0155e-01],\n",
      "          [-6.1424e-03, -3.9788e-02, -3.0385e-02],\n",
      "          [-4.2424e-02, -1.6632e-01,  1.3752e-01]],\n",
      "\n",
      "         [[ 9.5750e-02, -1.9068e-01,  9.3779e-02],\n",
      "          [-1.4504e-01, -7.9963e-02,  1.6530e-01],\n",
      "          [-1.7009e-02,  1.2287e-01,  1.1117e-01]],\n",
      "\n",
      "         [[ 1.8041e-02, -1.8453e-01,  1.3486e-01],\n",
      "          [-8.0501e-02, -1.2605e-01, -6.2647e-02],\n",
      "          [ 1.5494e-01, -5.2710e-02,  8.1234e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0754e-02, -9.2367e-02,  2.8545e-02],\n",
      "          [ 1.5158e-01,  1.5685e-01, -4.9259e-04],\n",
      "          [ 1.7678e-02,  1.1556e-01, -7.0583e-02]],\n",
      "\n",
      "         [[-3.6899e-02,  1.0027e-01,  1.3537e-01],\n",
      "          [ 2.3768e-02, -1.8971e-02, -1.6487e-01],\n",
      "          [-1.4784e-02, -1.2772e-01, -3.7394e-02]],\n",
      "\n",
      "         [[-3.2230e-03,  7.3699e-02,  1.6497e-01],\n",
      "          [ 1.2768e-02,  2.9490e-02, -8.6113e-02],\n",
      "          [-1.4008e-01, -1.7189e-01,  4.1347e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7288e-02,  1.6959e-01,  1.1088e-01],\n",
      "          [ 6.8938e-03, -6.1551e-02,  1.3321e-01],\n",
      "          [-1.6707e-01, -5.8091e-03,  6.7720e-02]],\n",
      "\n",
      "         [[-1.8844e-01,  1.4844e-01, -4.8900e-02],\n",
      "          [ 1.6478e-01, -3.3672e-02, -1.1533e-01],\n",
      "          [ 9.3720e-02, -1.2403e-01, -1.3606e-01]],\n",
      "\n",
      "         [[-5.7864e-02,  1.1827e-01,  6.3501e-02],\n",
      "          [ 1.5077e-01, -6.5508e-02, -1.5646e-05],\n",
      "          [-6.2990e-02,  1.8357e-01,  1.4429e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.7924e-01,  4.0163e-02, -1.3476e-01],\n",
      "          [ 2.6072e-02,  5.2021e-02, -9.4968e-02],\n",
      "          [-1.7126e-01, -1.9211e-02, -1.3133e-01]],\n",
      "\n",
      "         [[ 1.8814e-01, -7.8810e-02, -4.4525e-02],\n",
      "          [ 1.4126e-01, -3.2298e-02,  1.2882e-03],\n",
      "          [-1.9148e-01,  8.3776e-02,  1.3669e-01]],\n",
      "\n",
      "         [[-1.8722e-01,  1.8546e-01,  1.2910e-01],\n",
      "          [ 9.7616e-02, -6.4649e-03, -2.0501e-02],\n",
      "          [ 1.7494e-01,  9.4139e-02, -1.0893e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0546e-01,  1.7186e-01, -1.0180e-01],\n",
      "          [-6.6518e-02, -1.3784e-01,  5.9292e-02],\n",
      "          [-3.7935e-02,  1.7243e-01, -8.6736e-02]],\n",
      "\n",
      "         [[ 5.6252e-02, -1.2641e-01, -1.3248e-01],\n",
      "          [-1.7840e-01,  2.7354e-03,  4.6000e-02],\n",
      "          [ 8.1731e-02,  1.8850e-01,  9.3190e-02]],\n",
      "\n",
      "         [[ 3.1818e-04,  1.0676e-01, -1.7900e-01],\n",
      "          [ 1.8472e-01, -1.6280e-01,  1.1154e-01],\n",
      "          [-1.1627e-01,  1.8373e-01,  5.3883e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.1670e-02,  6.0638e-02, -8.6556e-02],\n",
      "          [ 9.7051e-03,  5.0995e-02,  5.9052e-02],\n",
      "          [ 5.8124e-02,  1.5813e-01, -2.4859e-02]],\n",
      "\n",
      "         [[-1.1855e-01,  9.1182e-02,  1.4527e-01],\n",
      "          [ 1.3877e-01, -1.3102e-01, -2.5272e-03],\n",
      "          [ 4.6360e-02, -3.8430e-03,  8.8354e-02]],\n",
      "\n",
      "         [[-1.7851e-01,  1.0582e-01, -5.6905e-02],\n",
      "          [ 3.4937e-02, -4.0136e-02, -1.7256e-01],\n",
      "          [ 7.5924e-02,  3.4510e-03, -1.7500e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4888e-01,  1.6461e-01, -8.3193e-02],\n",
      "          [-5.1734e-02, -5.7884e-02, -1.3667e-01],\n",
      "          [-1.7354e-01, -8.5850e-02, -1.0940e-01]],\n",
      "\n",
      "         [[-2.9000e-02, -1.6776e-02,  1.3641e-01],\n",
      "          [-1.6816e-02,  1.0080e-01, -1.8538e-01],\n",
      "          [-1.8436e-02, -2.9707e-02,  6.0059e-02]],\n",
      "\n",
      "         [[ 1.3236e-01,  1.2946e-01,  3.7335e-02],\n",
      "          [ 8.2605e-02,  1.4030e-01,  1.5926e-01],\n",
      "          [ 7.8784e-02, -1.3289e-01,  1.2655e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5238e-02,  1.3401e-01,  6.2661e-02],\n",
      "          [ 5.3095e-02,  1.4879e-02,  1.2441e-01],\n",
      "          [ 1.5288e-01,  1.9054e-01, -1.6427e-01]],\n",
      "\n",
      "         [[ 9.5791e-02,  1.5518e-01, -9.9860e-02],\n",
      "          [-1.6841e-01,  1.0084e-01,  2.1914e-02],\n",
      "          [ 1.5766e-01,  8.0793e-02,  1.4685e-01]],\n",
      "\n",
      "         [[-1.6103e-01, -5.8938e-02, -1.8284e-01],\n",
      "          [ 2.9763e-02,  1.2698e-01, -1.3589e-01],\n",
      "          [ 1.2741e-01, -1.6872e-01,  1.2980e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6081e-01, -1.4980e-01, -9.7765e-02],\n",
      "          [ 5.4653e-02, -1.7428e-01,  9.1062e-02],\n",
      "          [-1.8066e-01, -1.5501e-02, -6.1580e-02]],\n",
      "\n",
      "         [[-3.5864e-02, -1.2375e-01,  1.8746e-01],\n",
      "          [ 1.7736e-01, -1.9201e-01, -2.6987e-02],\n",
      "          [-1.4917e-01, -1.6315e-01, -6.5009e-02]],\n",
      "\n",
      "         [[ 1.2185e-01, -1.7815e-01,  1.7828e-01],\n",
      "          [ 1.6959e-01,  8.0490e-02,  1.4418e-01],\n",
      "          [ 3.1415e-02,  9.5015e-02,  9.9405e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.7170e-01,  4.9317e-02, -7.0028e-03],\n",
      "          [-1.8589e-01,  1.4940e-01, -6.0677e-02],\n",
      "          [ 2.6533e-02, -9.7064e-02,  1.2263e-01]],\n",
      "\n",
      "         [[ 1.1985e-02, -7.2381e-02, -8.6343e-02],\n",
      "          [ 4.8246e-02, -1.6858e-01,  8.1726e-02],\n",
      "          [-1.6270e-01, -1.2099e-01,  2.6335e-02]],\n",
      "\n",
      "         [[-1.0360e-01,  6.2303e-02, -1.2382e-01],\n",
      "          [-6.2578e-02,  7.6962e-02,  1.0013e-01],\n",
      "          [-4.4362e-02,  6.6248e-02, -1.4995e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.8724e-02,  1.2044e-01, -1.6778e-02],\n",
      "          [-1.6831e-01, -1.8744e-02, -2.8747e-02],\n",
      "          [ 6.6054e-02, -3.9920e-02, -1.3274e-01]],\n",
      "\n",
      "         [[ 3.8037e-02,  1.4200e-01, -4.5641e-02],\n",
      "          [ 5.5756e-02,  3.2002e-02,  3.0409e-02],\n",
      "          [-2.9156e-02, -1.1834e-02, -1.8540e-01]],\n",
      "\n",
      "         [[ 1.1412e-01, -1.1540e-01, -1.4989e-01],\n",
      "          [-1.1552e-01,  5.5035e-02, -3.8707e-02],\n",
      "          [-1.1274e-01,  1.0699e-01, -9.4603e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3470e-01,  9.2714e-02, -8.0450e-02],\n",
      "          [-1.2642e-01, -5.8161e-02, -9.4270e-02],\n",
      "          [ 2.2381e-03, -8.3198e-02,  6.6394e-03]],\n",
      "\n",
      "         [[-1.1888e-02,  1.3241e-01,  1.2039e-01],\n",
      "          [-9.3599e-02,  7.3486e-02, -1.7133e-01],\n",
      "          [-1.5081e-01, -1.3132e-01, -8.2428e-02]],\n",
      "\n",
      "         [[-1.8357e-01,  1.1204e-01,  1.6152e-01],\n",
      "          [-1.4989e-01, -1.7596e-01, -5.7936e-02],\n",
      "          [ 1.5041e-01,  5.2253e-02,  1.0894e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8373e-01,  1.5349e-01,  9.1996e-02],\n",
      "          [-9.8139e-02, -4.8651e-02, -3.1596e-02],\n",
      "          [-3.4255e-02,  4.5479e-02,  1.2084e-01]],\n",
      "\n",
      "         [[-1.0845e-01, -1.8722e-01, -1.6810e-01],\n",
      "          [ 5.0999e-02, -1.2441e-01,  9.5385e-02],\n",
      "          [ 6.0679e-02,  5.7609e-02, -7.3215e-02]],\n",
      "\n",
      "         [[ 9.6534e-02,  1.3266e-01,  6.1819e-02],\n",
      "          [ 1.1462e-02,  8.2749e-02,  2.2215e-02],\n",
      "          [ 4.7442e-02,  7.7332e-02,  1.7220e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.2091e-02,  9.7727e-02,  1.4854e-01],\n",
      "          [-1.5589e-01, -4.0857e-03, -1.6104e-01],\n",
      "          [-1.4373e-01,  1.2245e-01, -1.4838e-01]],\n",
      "\n",
      "         [[ 1.8013e-01,  1.7085e-01, -1.2812e-01],\n",
      "          [-1.7082e-01, -3.1278e-02, -1.7416e-01],\n",
      "          [ 9.9634e-02, -6.5373e-02,  4.3205e-02]],\n",
      "\n",
      "         [[-2.4325e-03, -1.7316e-02, -1.0776e-01],\n",
      "          [ 5.1357e-02,  7.2619e-02,  1.4798e-02],\n",
      "          [-9.4669e-03, -7.3142e-02, -8.5548e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.4702e-02,  7.8626e-02, -7.9250e-02],\n",
      "          [-8.4551e-02,  1.6267e-01,  1.2350e-01],\n",
      "          [-1.8275e-01, -1.1192e-01, -5.7238e-03]],\n",
      "\n",
      "         [[-8.0594e-02,  1.8255e-02, -7.1122e-02],\n",
      "          [-1.9241e-01, -1.3916e-01,  1.2194e-01],\n",
      "          [ 3.3404e-02,  1.7798e-01,  1.6028e-01]],\n",
      "\n",
      "         [[-2.0632e-02,  1.0920e-01, -3.0436e-02],\n",
      "          [ 9.5280e-02, -1.5001e-01, -6.6393e-02],\n",
      "          [ 6.1603e-03,  3.1256e-02,  6.6234e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7409e-01,  1.6398e-01, -1.3269e-01],\n",
      "          [-2.7976e-02, -7.2318e-03,  7.0604e-02],\n",
      "          [-1.3005e-01,  8.1663e-02,  6.0397e-02]],\n",
      "\n",
      "         [[ 1.1517e-01, -5.5561e-02,  2.7741e-02],\n",
      "          [ 1.0368e-01,  1.7293e-01, -5.6926e-02],\n",
      "          [ 1.0628e-01, -6.7507e-02,  9.3369e-02]],\n",
      "\n",
      "         [[-6.1240e-02,  3.5626e-02, -1.5327e-01],\n",
      "          [ 6.0923e-02, -1.3705e-01, -1.0503e-01],\n",
      "          [-7.2536e-02, -6.4247e-02,  1.4585e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4786e-01,  1.1120e-01, -1.0408e-01],\n",
      "          [ 1.4163e-01,  1.7991e-01, -2.5697e-02],\n",
      "          [-1.1052e-01,  1.5459e-01,  1.7632e-01]],\n",
      "\n",
      "         [[ 6.8043e-02, -1.8875e-01, -1.3050e-01],\n",
      "          [ 1.3048e-01, -1.7322e-01,  8.0776e-02],\n",
      "          [ 1.1216e-01, -5.8131e-02, -1.8168e-01]],\n",
      "\n",
      "         [[-1.6645e-01,  1.5845e-01,  7.3223e-02],\n",
      "          [ 9.2112e-02, -9.9340e-02, -7.7179e-02],\n",
      "          [ 1.0313e-01, -1.3127e-01,  9.9914e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.1237e-03,  1.1557e-01, -1.0997e-01],\n",
      "          [-7.3758e-02, -1.4393e-01,  1.0490e-01],\n",
      "          [-3.9073e-02, -6.6225e-02, -1.8733e-01]],\n",
      "\n",
      "         [[ 1.6254e-01,  1.7620e-01, -1.1102e-01],\n",
      "          [-3.4193e-02, -6.3573e-02, -1.2134e-01],\n",
      "          [-1.3570e-01, -2.5312e-02,  9.0008e-02]],\n",
      "\n",
      "         [[-1.2903e-01,  1.9089e-01, -2.9673e-02],\n",
      "          [-1.3354e-01, -1.1135e-01,  1.9168e-01],\n",
      "          [-3.0810e-02,  1.0909e-01,  1.8316e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5872e-01, -1.4327e-01,  6.1235e-02],\n",
      "          [ 8.2553e-02, -5.4813e-02, -1.1534e-01],\n",
      "          [-3.6418e-02, -1.8604e-02, -1.1219e-01]],\n",
      "\n",
      "         [[-1.5733e-01,  6.4945e-02,  2.3688e-02],\n",
      "          [-1.1717e-01, -5.3830e-02, -1.1929e-02],\n",
      "          [ 8.8831e-02,  7.4931e-02,  1.6880e-01]],\n",
      "\n",
      "         [[ 1.9220e-02,  5.8056e-02, -1.4387e-01],\n",
      "          [ 8.1829e-02, -8.2150e-02,  1.4092e-01],\n",
      "          [ 5.0688e-02, -1.8074e-02, -6.8224e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.2551e-02,  7.9353e-02,  5.2666e-02],\n",
      "          [ 3.0794e-02, -1.5028e-01, -1.0082e-01],\n",
      "          [-1.9145e-01, -6.7216e-02, -8.9287e-02]],\n",
      "\n",
      "         [[-3.8327e-02,  1.4027e-01,  4.6465e-02],\n",
      "          [ 8.4977e-02,  8.1549e-02,  1.5678e-01],\n",
      "          [ 1.5298e-01,  3.9024e-02,  1.6438e-01]],\n",
      "\n",
      "         [[-1.7117e-01,  1.0389e-01,  1.2875e-01],\n",
      "          [-1.8239e-01, -1.6381e-01, -3.0868e-02],\n",
      "          [ 8.2346e-02,  1.6245e-01, -1.7509e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7573e-01, -1.4750e-02, -4.4387e-02],\n",
      "          [-4.9007e-02,  1.2696e-01,  8.9876e-02],\n",
      "          [ 1.7398e-02, -1.6122e-01, -1.4402e-02]],\n",
      "\n",
      "         [[-1.5545e-01, -1.9104e-01,  6.6328e-02],\n",
      "          [-4.8486e-02, -1.8412e-01, -1.5964e-01],\n",
      "          [ 1.8472e-01,  1.8007e-01, -1.3573e-01]],\n",
      "\n",
      "         [[-9.6574e-02,  1.1582e-01, -4.0598e-02],\n",
      "          [-1.5634e-02, -5.7306e-02,  9.3079e-02],\n",
      "          [-1.7897e-01, -1.7490e-01,  7.3848e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.5861e-02,  1.0770e-01, -5.7113e-02],\n",
      "          [-8.4737e-02, -9.3298e-02, -1.0394e-01],\n",
      "          [-1.6772e-01,  7.3122e-02, -8.4503e-02]],\n",
      "\n",
      "         [[-1.8675e-01,  3.0324e-02,  1.5388e-01],\n",
      "          [-7.9205e-03, -1.5669e-01,  1.0247e-01],\n",
      "          [-1.0512e-01,  1.2118e-01, -1.3236e-01]],\n",
      "\n",
      "         [[ 1.7449e-01, -4.6581e-02,  1.7676e-01],\n",
      "          [ 9.0901e-02,  1.4307e-01,  3.5001e-02],\n",
      "          [-1.1206e-01,  2.0157e-02,  1.5720e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6726e-01,  5.3119e-02,  2.8379e-02],\n",
      "          [ 1.2899e-01, -1.3213e-01, -1.4114e-01],\n",
      "          [ 5.1908e-02, -5.4484e-02, -6.6067e-02]],\n",
      "\n",
      "         [[ 4.3255e-02,  1.5241e-01, -1.4426e-01],\n",
      "          [-9.8819e-03, -8.0253e-02, -2.3688e-02],\n",
      "          [-8.4167e-02,  1.8333e-01,  1.0697e-01]],\n",
      "\n",
      "         [[ 4.1701e-02, -5.4291e-02,  1.1909e-01],\n",
      "          [-1.0674e-01, -1.7303e-01, -1.2910e-01],\n",
      "          [-5.6907e-02, -1.3188e-01,  1.2255e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0357e-02, -7.2214e-02, -1.3155e-01],\n",
      "          [ 1.6823e-01,  1.7701e-01, -1.1573e-01],\n",
      "          [ 1.5992e-01, -1.7357e-02, -7.1129e-02]],\n",
      "\n",
      "         [[ 7.1644e-02, -1.5051e-01, -1.7606e-01],\n",
      "          [-1.5927e-02,  1.2688e-01,  1.3963e-01],\n",
      "          [ 1.6445e-01,  9.9338e-02,  4.8243e-02]],\n",
      "\n",
      "         [[ 2.7104e-02, -1.1596e-01,  1.5747e-01],\n",
      "          [ 1.5905e-01, -1.6579e-01, -1.8271e-01],\n",
      "          [-4.6580e-02, -1.2326e-01, -6.7574e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6729e-01, -3.7923e-02,  1.7401e-01],\n",
      "          [-1.6773e-02,  1.5661e-02, -7.8601e-03],\n",
      "          [-5.7089e-02, -3.2308e-02, -9.0418e-02]],\n",
      "\n",
      "         [[-1.3887e-01,  1.4090e-02,  4.1216e-02],\n",
      "          [ 4.3543e-02,  4.5262e-02, -7.1461e-02],\n",
      "          [-1.8381e-01,  9.2303e-02,  3.6103e-02]],\n",
      "\n",
      "         [[-1.8252e-01,  1.8233e-01, -4.7137e-02],\n",
      "          [-1.5847e-01, -1.1769e-01, -4.9178e-02],\n",
      "          [-1.5167e-01,  3.4963e-02, -1.0133e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0440e-01,  1.6824e-01, -6.4238e-02],\n",
      "          [-6.0437e-03, -1.1055e-01, -2.2560e-02],\n",
      "          [-1.2153e-01, -1.0722e-01, -1.2636e-01]],\n",
      "\n",
      "         [[-7.1065e-02,  4.4609e-02,  8.4180e-02],\n",
      "          [ 1.1138e-01, -9.2998e-02, -1.4392e-01],\n",
      "          [-2.8582e-02,  1.7907e-01,  5.6620e-03]],\n",
      "\n",
      "         [[ 1.7938e-01,  1.4822e-01,  1.2965e-01],\n",
      "          [-1.7818e-02,  3.0660e-02, -1.2613e-01],\n",
      "          [ 3.0588e-02,  6.8393e-02, -1.2157e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.3491e-01, -9.7329e-02,  2.1668e-03],\n",
      "          [-3.5047e-02,  7.6280e-02, -9.6350e-02],\n",
      "          [ 1.8039e-01, -9.2444e-02,  1.1747e-01]],\n",
      "\n",
      "         [[ 1.7133e-01,  1.7499e-01, -9.3608e-02],\n",
      "          [-1.0199e-01, -8.2009e-02, -1.2864e-01],\n",
      "          [-4.9670e-02, -5.5888e-02,  7.0293e-02]],\n",
      "\n",
      "         [[ 1.6672e-01,  7.0921e-02,  1.9897e-03],\n",
      "          [-6.8078e-02, -5.6701e-02,  1.6301e-01],\n",
      "          [-1.6597e-01, -2.4231e-02, -1.8617e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.9463e-02, -1.4235e-01, -1.8699e-01],\n",
      "          [ 6.4884e-02, -1.0004e-01,  4.2418e-02],\n",
      "          [ 1.6889e-01, -3.2201e-02,  6.9675e-02]],\n",
      "\n",
      "         [[-7.9010e-02,  1.2552e-01,  1.8349e-01],\n",
      "          [-7.1628e-02, -1.5028e-01,  1.4735e-01],\n",
      "          [ 1.3443e-01,  8.4271e-02,  1.2106e-02]],\n",
      "\n",
      "         [[ 5.9095e-02,  4.3864e-02,  2.7143e-02],\n",
      "          [-6.4916e-02,  4.8531e-02,  1.7024e-01],\n",
      "          [-6.0359e-02, -1.5196e-01, -1.3784e-01]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0051,  0.0711,  0.0202,  0.1772,  0.0565,  0.0851, -0.1731,  0.1133,\n",
      "         0.1264,  0.0402,  0.0711, -0.1786,  0.1780, -0.0143, -0.1891,  0.0673,\n",
      "         0.1129,  0.1240,  0.1762,  0.0314,  0.1104,  0.1879,  0.0838,  0.0738,\n",
      "        -0.0206, -0.1422,  0.0649, -0.1399,  0.0025, -0.1805, -0.1856, -0.0860],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for para in model.conv1.parameters():\n",
    "     #para.requires_grad = False\n",
    "        print(para)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75612f34",
   "metadata": {},
   "source": [
    "# Step 3 Pass in the model to start training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78656153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/40]\t|\tStep: [9/27]\t|\tLoss: 0.0010\n",
      "Epoch: [1/40]\t|\tStep: [18/27]\t|\tLoss: 0.0010\n",
      "Epoch: [1/40]\t|\tStep: [27/27]\t|\tLoss: 0.0015\n",
      "100.0\n",
      "epoch: 01 | Accuracy: 100.00 Loss: 0.0282\n",
      "\n",
      "Epoch: [2/40]\t|\tStep: [9/27]\t|\tLoss: 0.0011\n",
      "Epoch: [2/40]\t|\tStep: [18/27]\t|\tLoss: 0.0007\n",
      "Epoch: [2/40]\t|\tStep: [27/27]\t|\tLoss: 0.0020\n",
      "100.0\n",
      "epoch: 02 | Accuracy: 100.00 Loss: 0.0281\n",
      "\n",
      "Epoch: [3/40]\t|\tStep: [9/27]\t|\tLoss: 0.0009\n",
      "Epoch: [3/40]\t|\tStep: [18/27]\t|\tLoss: 0.0007\n",
      "Epoch: [3/40]\t|\tStep: [27/27]\t|\tLoss: 0.0014\n",
      "100.0\n",
      "epoch: 03 | Accuracy: 100.00 Loss: 0.0262\n",
      "\n",
      "Epoch: [4/40]\t|\tStep: [9/27]\t|\tLoss: 0.0010\n",
      "Epoch: [4/40]\t|\tStep: [18/27]\t|\tLoss: 0.0006\n",
      "Epoch: [4/40]\t|\tStep: [27/27]\t|\tLoss: 0.0010\n",
      "100.0\n",
      "epoch: 04 | Accuracy: 100.00 Loss: 0.0259\n",
      "\n",
      "Epoch: [5/40]\t|\tStep: [9/27]\t|\tLoss: 0.0010\n",
      "Epoch: [5/40]\t|\tStep: [18/27]\t|\tLoss: 0.0012\n",
      "Epoch: [5/40]\t|\tStep: [27/27]\t|\tLoss: 0.0034\n",
      "100.0\n",
      "epoch: 05 | Accuracy: 100.00 Loss: 0.0286\n",
      "\n",
      "Epoch: [6/40]\t|\tStep: [9/27]\t|\tLoss: 0.0009\n",
      "Epoch: [6/40]\t|\tStep: [18/27]\t|\tLoss: 0.0009\n",
      "Epoch: [6/40]\t|\tStep: [27/27]\t|\tLoss: 0.0020\n",
      "100.0\n",
      "epoch: 06 | Accuracy: 100.00 Loss: 0.0266\n",
      "\n",
      "Epoch: [7/40]\t|\tStep: [9/27]\t|\tLoss: 0.0007\n",
      "Epoch: [7/40]\t|\tStep: [18/27]\t|\tLoss: 0.0010\n",
      "Epoch: [7/40]\t|\tStep: [27/27]\t|\tLoss: 0.0009\n",
      "100.0\n",
      "epoch: 07 | Accuracy: 100.00 Loss: 0.0246\n",
      "\n",
      "Epoch: [8/40]\t|\tStep: [9/27]\t|\tLoss: 0.0007\n",
      "Epoch: [8/40]\t|\tStep: [18/27]\t|\tLoss: 0.0007\n",
      "Epoch: [8/40]\t|\tStep: [27/27]\t|\tLoss: 0.0011\n",
      "100.0\n",
      "epoch: 08 | Accuracy: 100.00 Loss: 0.0237\n",
      "\n",
      "Epoch: [9/40]\t|\tStep: [9/27]\t|\tLoss: 0.0007\n",
      "Epoch: [9/40]\t|\tStep: [18/27]\t|\tLoss: 0.0011\n",
      "Epoch: [9/40]\t|\tStep: [27/27]\t|\tLoss: 0.0020\n",
      "100.0\n",
      "epoch: 09 | Accuracy: 100.00 Loss: 0.0254\n",
      "\n",
      "Epoch: [10/40]\t|\tStep: [9/27]\t|\tLoss: 0.0009\n",
      "Epoch: [10/40]\t|\tStep: [18/27]\t|\tLoss: 0.0006\n",
      "Epoch: [10/40]\t|\tStep: [27/27]\t|\tLoss: 0.0020\n",
      "100.0\n",
      "epoch: 10 | Accuracy: 100.00 Loss: 0.0239\n",
      "\n",
      "Epoch: [11/40]\t|\tStep: [9/27]\t|\tLoss: 0.0010\n",
      "Epoch: [11/40]\t|\tStep: [18/27]\t|\tLoss: 0.0009\n",
      "Epoch: [11/40]\t|\tStep: [27/27]\t|\tLoss: 0.0013\n",
      "100.0\n",
      "epoch: 11 | Accuracy: 100.00 Loss: 0.0237\n",
      "\n",
      "Epoch: [12/40]\t|\tStep: [9/27]\t|\tLoss: 0.0006\n",
      "Epoch: [12/40]\t|\tStep: [18/27]\t|\tLoss: 0.0008\n",
      "Epoch: [12/40]\t|\tStep: [27/27]\t|\tLoss: 0.0038\n",
      "100.0\n",
      "epoch: 12 | Accuracy: 100.00 Loss: 0.0254\n",
      "\n",
      "Epoch: [13/40]\t|\tStep: [9/27]\t|\tLoss: 0.0010\n",
      "Epoch: [13/40]\t|\tStep: [18/27]\t|\tLoss: 0.0008\n",
      "Epoch: [13/40]\t|\tStep: [27/27]\t|\tLoss: 0.0021\n",
      "100.0\n",
      "epoch: 13 | Accuracy: 100.00 Loss: 0.0224\n",
      "\n",
      "Epoch: [14/40]\t|\tStep: [9/27]\t|\tLoss: 0.0012\n",
      "Epoch: [14/40]\t|\tStep: [18/27]\t|\tLoss: 0.0007\n",
      "Epoch: [14/40]\t|\tStep: [27/27]\t|\tLoss: 0.0013\n",
      "100.0\n",
      "epoch: 14 | Accuracy: 100.00 Loss: 0.0213\n",
      "\n",
      "Epoch: [15/40]\t|\tStep: [9/27]\t|\tLoss: 0.0006\n",
      "Epoch: [15/40]\t|\tStep: [18/27]\t|\tLoss: 0.0008\n",
      "Epoch: [15/40]\t|\tStep: [27/27]\t|\tLoss: 0.0035\n",
      "100.0\n",
      "epoch: 15 | Accuracy: 100.00 Loss: 0.0227\n",
      "\n",
      "Epoch: [16/40]\t|\tStep: [9/27]\t|\tLoss: 0.0008\n",
      "Epoch: [16/40]\t|\tStep: [18/27]\t|\tLoss: 0.0006\n",
      "Epoch: [16/40]\t|\tStep: [27/27]\t|\tLoss: 0.0032\n",
      "100.0\n",
      "epoch: 16 | Accuracy: 100.00 Loss: 0.0233\n",
      "\n",
      "Epoch: [17/40]\t|\tStep: [9/27]\t|\tLoss: 0.0005\n",
      "Epoch: [17/40]\t|\tStep: [18/27]\t|\tLoss: 0.0005\n",
      "Epoch: [17/40]\t|\tStep: [27/27]\t|\tLoss: 0.0010\n",
      "100.0\n",
      "epoch: 17 | Accuracy: 100.00 Loss: 0.0202\n",
      "\n",
      "Epoch: [18/40]\t|\tStep: [9/27]\t|\tLoss: 0.0010\n",
      "Epoch: [18/40]\t|\tStep: [18/27]\t|\tLoss: 0.0007\n",
      "Epoch: [18/40]\t|\tStep: [27/27]\t|\tLoss: 0.0007\n",
      "100.0\n",
      "epoch: 18 | Accuracy: 100.00 Loss: 0.0201\n",
      "\n",
      "Epoch: [19/40]\t|\tStep: [9/27]\t|\tLoss: 0.0007\n",
      "Epoch: [19/40]\t|\tStep: [18/27]\t|\tLoss: 0.0006\n",
      "Epoch: [19/40]\t|\tStep: [27/27]\t|\tLoss: 0.0010\n",
      "100.0\n",
      "epoch: 19 | Accuracy: 100.00 Loss: 0.0187\n",
      "\n",
      "Epoch: [20/40]\t|\tStep: [9/27]\t|\tLoss: 0.0005\n",
      "Epoch: [20/40]\t|\tStep: [18/27]\t|\tLoss: 0.0006\n",
      "Epoch: [20/40]\t|\tStep: [27/27]\t|\tLoss: 0.0005\n",
      "100.0\n",
      "epoch: 20 | Accuracy: 100.00 Loss: 0.0190\n",
      "\n",
      "Epoch: [21/40]\t|\tStep: [9/27]\t|\tLoss: 0.0006\n",
      "Epoch: [21/40]\t|\tStep: [18/27]\t|\tLoss: 0.0005\n",
      "Epoch: [21/40]\t|\tStep: [27/27]\t|\tLoss: 0.0130\n",
      "100.0\n",
      "epoch: 21 | Accuracy: 100.00 Loss: 0.0300\n",
      "\n",
      "Epoch: [22/40]\t|\tStep: [9/27]\t|\tLoss: 0.0006\n",
      "Epoch: [22/40]\t|\tStep: [18/27]\t|\tLoss: 0.0009\n",
      "Epoch: [22/40]\t|\tStep: [27/27]\t|\tLoss: 0.0024\n",
      "100.0\n",
      "epoch: 22 | Accuracy: 100.00 Loss: 0.0206\n",
      "\n",
      "Epoch: [23/40]\t|\tStep: [9/27]\t|\tLoss: 0.0007\n",
      "Epoch: [23/40]\t|\tStep: [18/27]\t|\tLoss: 0.0014\n",
      "Epoch: [23/40]\t|\tStep: [27/27]\t|\tLoss: 0.0020\n",
      "100.0\n",
      "epoch: 23 | Accuracy: 100.00 Loss: 0.0206\n",
      "\n",
      "Epoch: [24/40]\t|\tStep: [9/27]\t|\tLoss: 0.0006\n",
      "Epoch: [24/40]\t|\tStep: [18/27]\t|\tLoss: 0.0005\n",
      "Epoch: [24/40]\t|\tStep: [27/27]\t|\tLoss: 0.0021\n",
      "100.0\n",
      "epoch: 24 | Accuracy: 100.00 Loss: 0.0201\n",
      "\n",
      "Epoch: [25/40]\t|\tStep: [9/27]\t|\tLoss: 0.0007\n",
      "Epoch: [25/40]\t|\tStep: [18/27]\t|\tLoss: 0.0005\n",
      "Epoch: [25/40]\t|\tStep: [27/27]\t|\tLoss: 0.0003\n",
      "100.0\n",
      "epoch: 25 | Accuracy: 100.00 Loss: 0.0167\n",
      "\n",
      "Epoch: [26/40]\t|\tStep: [9/27]\t|\tLoss: 0.0008\n",
      "Epoch: [26/40]\t|\tStep: [18/27]\t|\tLoss: 0.0005\n",
      "Epoch: [26/40]\t|\tStep: [27/27]\t|\tLoss: 0.0016\n",
      "100.0\n",
      "epoch: 26 | Accuracy: 100.00 Loss: 0.0181\n",
      "\n",
      "Epoch: [27/40]\t|\tStep: [9/27]\t|\tLoss: 0.0008\n",
      "Epoch: [27/40]\t|\tStep: [18/27]\t|\tLoss: 0.0006\n",
      "Epoch: [27/40]\t|\tStep: [27/27]\t|\tLoss: 0.0008\n",
      "100.0\n",
      "epoch: 27 | Accuracy: 100.00 Loss: 0.0165\n",
      "\n",
      "Epoch: [28/40]\t|\tStep: [9/27]\t|\tLoss: 0.0006\n",
      "Epoch: [28/40]\t|\tStep: [18/27]\t|\tLoss: 0.0006\n",
      "Epoch: [28/40]\t|\tStep: [27/27]\t|\tLoss: 0.0003\n",
      "100.0\n",
      "epoch: 28 | Accuracy: 100.00 Loss: 0.0179\n",
      "\n",
      "Epoch: [29/40]\t|\tStep: [9/27]\t|\tLoss: 0.0007\n",
      "Epoch: [29/40]\t|\tStep: [18/27]\t|\tLoss: 0.0004\n",
      "Epoch: [29/40]\t|\tStep: [27/27]\t|\tLoss: 0.0007\n",
      "100.0\n",
      "epoch: 29 | Accuracy: 100.00 Loss: 0.0156\n",
      "\n",
      "Epoch: [30/40]\t|\tStep: [9/27]\t|\tLoss: 0.0006\n",
      "Epoch: [30/40]\t|\tStep: [18/27]\t|\tLoss: 0.0007\n",
      "Epoch: [30/40]\t|\tStep: [27/27]\t|\tLoss: 0.0018\n",
      "100.0\n",
      "epoch: 30 | Accuracy: 100.00 Loss: 0.0169\n",
      "\n",
      "Epoch: [31/40]\t|\tStep: [9/27]\t|\tLoss: 0.0005\n",
      "Epoch: [31/40]\t|\tStep: [18/27]\t|\tLoss: 0.0003\n",
      "Epoch: [31/40]\t|\tStep: [27/27]\t|\tLoss: 0.0018\n",
      "100.0\n",
      "epoch: 31 | Accuracy: 100.00 Loss: 0.0158\n",
      "\n",
      "Epoch: [32/40]\t|\tStep: [9/27]\t|\tLoss: 0.0005\n",
      "Epoch: [32/40]\t|\tStep: [18/27]\t|\tLoss: 0.0007\n",
      "Epoch: [32/40]\t|\tStep: [27/27]\t|\tLoss: 0.0003\n",
      "100.0\n",
      "epoch: 32 | Accuracy: 100.00 Loss: 0.0142\n",
      "\n",
      "Epoch: [33/40]\t|\tStep: [9/27]\t|\tLoss: 0.0007\n",
      "Epoch: [33/40]\t|\tStep: [18/27]\t|\tLoss: 0.0006\n",
      "Epoch: [33/40]\t|\tStep: [27/27]\t|\tLoss: 0.0006\n",
      "100.0\n",
      "epoch: 33 | Accuracy: 100.00 Loss: 0.0128\n",
      "\n",
      "Epoch: [34/40]\t|\tStep: [9/27]\t|\tLoss: 0.0004\n",
      "Epoch: [34/40]\t|\tStep: [18/27]\t|\tLoss: 0.0003\n",
      "Epoch: [34/40]\t|\tStep: [27/27]\t|\tLoss: 0.0006\n",
      "100.0\n",
      "epoch: 34 | Accuracy: 100.00 Loss: 0.0115\n",
      "\n",
      "Epoch: [35/40]\t|\tStep: [9/27]\t|\tLoss: 0.0004\n",
      "Epoch: [35/40]\t|\tStep: [18/27]\t|\tLoss: 0.0004\n",
      "Epoch: [35/40]\t|\tStep: [27/27]\t|\tLoss: 0.0005\n",
      "100.0\n",
      "epoch: 35 | Accuracy: 100.00 Loss: 0.0115\n",
      "\n",
      "Epoch: [36/40]\t|\tStep: [9/27]\t|\tLoss: 0.0002\n",
      "Epoch: [36/40]\t|\tStep: [18/27]\t|\tLoss: 0.0003\n",
      "Epoch: [36/40]\t|\tStep: [27/27]\t|\tLoss: 0.0004\n",
      "100.0\n",
      "epoch: 36 | Accuracy: 100.00 Loss: 0.0103\n",
      "\n",
      "Epoch: [37/40]\t|\tStep: [9/27]\t|\tLoss: 0.0004\n",
      "Epoch: [37/40]\t|\tStep: [18/27]\t|\tLoss: 0.0002\n",
      "Epoch: [37/40]\t|\tStep: [27/27]\t|\tLoss: 0.0002\n",
      "100.0\n",
      "epoch: 37 | Accuracy: 100.00 Loss: 0.0090\n",
      "\n",
      "Epoch: [38/40]\t|\tStep: [9/27]\t|\tLoss: 0.0005\n",
      "Epoch: [38/40]\t|\tStep: [18/27]\t|\tLoss: 0.0003\n",
      "Epoch: [38/40]\t|\tStep: [27/27]\t|\tLoss: 0.0005\n",
      "100.0\n",
      "epoch: 38 | Accuracy: 100.00 Loss: 0.0094\n",
      "\n",
      "Epoch: [39/40]\t|\tStep: [9/27]\t|\tLoss: 0.0004\n",
      "Epoch: [39/40]\t|\tStep: [18/27]\t|\tLoss: 0.0003\n",
      "Epoch: [39/40]\t|\tStep: [27/27]\t|\tLoss: 0.0003\n",
      "100.0\n",
      "epoch: 39 | Accuracy: 100.00 Loss: 0.0082\n",
      "\n",
      "Epoch: [40/40]\t|\tStep: [9/27]\t|\tLoss: 0.0004\n",
      "Epoch: [40/40]\t|\tStep: [18/27]\t|\tLoss: 0.0003\n",
      "Epoch: [40/40]\t|\tStep: [27/27]\t|\tLoss: 0.0011\n",
      "100.0\n",
      "epoch: 40 | Accuracy: 100.00 Loss: 0.0087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model and record the accuracy and loss values for each epoch during training\n",
    "def train(num_epochs, model, loaders):\n",
    "    model.train()   \n",
    "    for para in model.conv0.parameters():\n",
    "        para.requires_grad = False\n",
    "    # The first stores the correct rate and the second stores the loss value\n",
    "    Accy_list = []\n",
    "    Loss_list = []\n",
    "    \n",
    "    total_step = len(loaders)    \n",
    "    for epoch in range(num_epochs):\n",
    "        if epoch == 30:\n",
    "            for para in model.conv0.parameters():\n",
    "                para.requires_grad = True\n",
    "            for para in model.conv1.parameters():\n",
    "                para.requires_grad = False\n",
    "            for para in model.conv2.parameters():\n",
    "                para.requires_grad = False\n",
    "            for para in model.conv3.parameters():\n",
    "                para.requires_grad = False    \n",
    "            for para in model.fc1.parameters():\n",
    "                para.requires_grad = False    \n",
    "            for para in model.fc2.parameters():\n",
    "                para.requires_grad = False    \n",
    "        correct = 0\n",
    "        L = 0\n",
    "        for i, (images, labels) in enumerate(loaders):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)              \n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            \n",
    "            # Clear the previous gradient \n",
    "            optimizer.zero_grad()           \n",
    "            \n",
    "            # Backpropagate and update the parameters\n",
    "            loss.backward()               \n",
    "            optimizer.step()                \n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).float().sum()\n",
    "            L += loss.item()\n",
    "            if (i+1) % 9 == 0:\n",
    "                print ('Epoch: [{}/{}]\\t|\\tStep: [{}/{}]\\t|\\tLoss: {:.4f}' \n",
    "                       .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "                \n",
    "        accuracy = 100 * correct / len(train_set)\n",
    "        print(accuracy.item())\n",
    "        print(\"epoch: {:02d} | Accuracy: {:.2f} Loss: {:.4f}\\n\"\n",
    "              .format(epoch + 1, accuracy, L))\n",
    "        \n",
    "        # Add the correct and lost values for this epoch to the corresponding list\n",
    "        Accy_list.append(accuracy.item())\n",
    "        Loss_list.append(L)\n",
    "              \n",
    "    return Accy_list, Loss_list\n",
    "\n",
    "\n",
    "Accy_list, Loss_list = train(num_epochs, model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3ff517e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n"
     ]
    }
   ],
   "source": [
    "print(Accy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e141dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.028217472252435982, 0.02812801126856357, 0.02615501917898655, 0.025901138549670577, 0.02859144570538774, 0.02657598431687802, 0.024592135392595083, 0.02368088421644643, 0.025389270507730544, 0.023931028554216027, 0.02367784292437136, 0.025439877528697252, 0.0223713792511262, 0.021276581683196127, 0.022676451480947435, 0.023276998748769984, 0.02015635755378753, 0.02007583127124235, 0.01869113859720528, 0.01901692434330471, 0.029991569957928732, 0.0205937908613123, 0.0206129978178069, 0.02014805216458626, 0.0167252367537003, 0.018065183307044208, 0.01651908431085758, 0.0179175155935809, 0.015592358075082302, 0.01692393480334431, 0.01580591287347488, 0.01418165271752514, 0.012818979157600552, 0.011487347830552608, 0.011479640379548073, 0.010273979103658348, 0.009005244195577689, 0.009413074774784036, 0.008205056612496264, 0.008665166955324821]\n"
     ]
    }
   ],
   "source": [
    "print(Loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0e3f55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data | Accuracy: 86.21 %, Loss: 15.3560 \n"
     ]
    }
   ],
   "source": [
    "# Test models\n",
    "def test(model, loaders):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        L = 0\n",
    "        for images, labels in loaders:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)              \n",
    "            outputs = model(images)\n",
    "            # Get the loss value and add it up\n",
    "            loss = loss_func(outputs, labels)\n",
    "            L += loss.item()\n",
    "            \n",
    "             # Get the correct number of predicted samples\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).float().sum()\n",
    "            \n",
    "    accuracy = (100 * correct / len(test_set))\n",
    "    print(\"Test data | Accuracy: {:.2f} %, Loss: {:.4f} \".format(accuracy, L))\n",
    "    \n",
    "    return accuracy, L\n",
    "\n",
    "Test_acc, Test_loss = test(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpe",
   "language": "python",
   "name": "hpe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
