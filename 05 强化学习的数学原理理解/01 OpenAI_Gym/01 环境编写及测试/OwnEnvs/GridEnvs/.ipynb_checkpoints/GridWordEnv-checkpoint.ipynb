{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d29837f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.4.0 (SDL 2.26.4, Python 3.10.11)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# 导入相关包\n",
    "import numpy as np\n",
    "import pygame\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8059461e",
   "metadata": {},
   "source": [
    "## 1. 环境属性定义，窗口，状态空间，动作空间，Reward，状态转移"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2e8f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 继承类以及定义元数据(属性) 与 初始化方法\n",
    "class GridWorldEnv(gym.Env):\n",
    "    metadata = {\"render_mode\": [\"human\", \"rgb_array\"], \"render_fps\": 4}\n",
    "\n",
    "    # 默认render_mode为None, size为5, 作为可改动属性\n",
    "    def __init__(self, render_mode=None, size=5):\n",
    "        self.size = size # The size of the square grid\n",
    "        self.window_size = 512 # windows size 表明是 pygame 游戏窗口大小\n",
    "        \n",
    "        # 然后定义观察空间与动作空间，两者都是必须定义\n",
    "            # 目前观察，该Space类有许多数据类型可供选择，基础数据类型与符合数据类型，甚至矢量空间单元(推测与神经网络有关，具体不了解)\n",
    "        self.observation_space = spaces.Dict(\n",
    "            {\n",
    "                # 其中 Box 前面两个值表明上下限，shape则是一行两列，后者数据类型为int\n",
    "                    # 另外隐藏seed，表明是否初始化随机生成，其中默认为seed=None, (作为采样工具等等)\n",
    "                \"agent\": spaces.Box(0, size-1, shape=(2,), dtype=int),\n",
    "                \"target\": spaces.Box(0, size-1, shape=(2,), dtype=int)\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # 动作空间，表明有4个方位\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        \n",
    "        # 定义动作对agent自身位置的改变\n",
    "        \"\"\"\n",
    "        The following dictionary maps abstract actions from `self.action_space` to\n",
    "        the direction we will walk in if that action is taken.\n",
    "        I.e. 0 corresponds to \"right\", 1 to \"up\" etc.\n",
    "        \"\"\"\n",
    "        self._action_to_direction = {\n",
    "            0: np.array([1,0]), # 横轴加1，向右，假设pygame坐标轴原点是在左下角\n",
    "            1: np.array([0,1]), # 纵轴加1，向上\n",
    "            2: np.array([-1,0]), # 向左\n",
    "            3: np.array([0,-1]), # 向下\n",
    "        }\n",
    "        \n",
    "        # assert 断言，明确肯定，如果表达式为false，那么触发异常\n",
    "            # 表明要么 render_mode 是空的，要么就在给定的元数据模式中\n",
    "        assert render_mode is None or render_mode in self.metadata[\"render_modes\"]\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        \"\"\"\n",
    "        If human-rendering is used, `self.window` will be a reference\n",
    "        to the window that we draw to. `self.clock` will be a clock that is used\n",
    "        to ensure that the environment is rendered at the correct framerate in\n",
    "        human-mode. They will remain `None` until human-mode is used for the\n",
    "        first time.\n",
    "        \"\"\"\n",
    "        \n",
    "        # 对以上总结，如果human-rendering被启用\n",
    "            # 那么self.window作为绘制窗口，clock则作为钟表记时，来确保在正确帧率下渲染\n",
    "            # 比如前者的 rendering_fps = 4, 每4帧渲染一次\n",
    "        self.window = None\n",
    "        self.clock = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531ee525",
   "metadata": {},
   "source": [
    "## 2. 私有方法获取环境的观察与信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4134e8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 私有方法 获取 观察空间，对于每个环境，必须有\n",
    "    '''\n",
    "    Since we will need to compute observations both in reset and step,\n",
    "    it is often convenient to have a (private) method _get_obs that translates the environment’s state into an observation. \n",
    "    However, this is not mandatory and you may as well compute observations in reset and step separately:\n",
    "    '''\n",
    "    def _get_obs(self):\n",
    "        return {\"agent\": self._agent_location, \"target\": self._target_location}\n",
    "\n",
    "    # 同样需要一个提供信息的私有方法\n",
    "    '''\n",
    "    We can also implement a similar method for the auxiliary information that is returned by step and reset. \n",
    "    In our case, we would like to provide the manhattan distance between the agent and the target:\n",
    "    '''\n",
    "    def _get_info(self):\n",
    "        return{\n",
    "            # 范数计算，ord 则表明计算形式，其中1表示1阶，即每一项绝对值相加\n",
    "                # 具体 ord 查看官方文档\n",
    "            \"distance\": np.linalg.norm(\n",
    "                self._agent_location - self._target_location, ord=1\n",
    "            )\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7ae52f",
   "metadata": {},
   "source": [
    "## 3. 重置环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78e9f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 重置方法，用来初始化一个新的环境\n",
    "        # 通常在有 done signal 时就需要重置环境\n",
    "        # 对于 agent 初始化随机位置使用 np.random()\n",
    "            # 如果使用随机数生成一般也不需要担心随机种子，但是要记住继承 super().reset(seed=seed)\n",
    "\n",
    "    # reset 方法应该返还一个元组\n",
    "        # 包含着初始状态 与 辅助信息\n",
    "        # 因此会使用到私有方法 _get_obs 与 _get_info\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        # 使用继承方法，来保证gym.env的随机种子相同，针对reset方法的继承\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        # 对于agent位置进行随机均匀初始化\n",
    "        self._agent_location = self.np_random.integers(0, self.size, size=2, dtype=int)\n",
    "\n",
    "        # 随机初始化target的位置，保证不等于agent的位置\n",
    "        self._target_location = self._agent_location\n",
    "        while np.array_equal(self._target_location, self._agent_location):\n",
    "            self._target_location = self.np_random.integers(\n",
    "                0, self.size, size=2, dtype=int\n",
    "            )\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        # 如果选定的渲染模式为 human 此时调用私有的 _render_frame 方法\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "\n",
    "        return observation, info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d77ed7b",
   "metadata": {},
   "source": [
    "## 4. 环境更新步骤 以及 返还对应元组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6b15b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # step,表明环境接受 agent 动作后发生的变化\n",
    "        # 理论上会返还一个 4元组 ， 对于其他环境，可能返还的状态数有所区别，关键看源代码中如何定义的\n",
    "        # 同样会使用 _get_obs 与  _get_info:\n",
    "\n",
    "    def step(self, action):\n",
    "        # 根据动作匹配环境改变direction\n",
    "        direction = self._action_to_direction[action]\n",
    "        # We use `np.clip` to make sure we don't leave the grid\n",
    "            # 使用 np.clip 方法就能直接保证不会出网格，只会撞墙\n",
    "        self._agent_location = np.clip(\n",
    "            self._agent_location + direction, 0, self.size - 1\n",
    "        )\n",
    "\n",
    "        # 假定 agent 抵达了目的地，此时改变四元组中的 done状态，同时给定 reward\n",
    "        # An episode is done iff the agent has reached the target\n",
    "        terminated = np.array_equal(self._agent_location, self._target_location)\n",
    "        reward = 1 if terminated else 0  # Binary sparse rewards\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "\n",
    "        # 对于该 false的理解目前为是否是提前终止，但是返回默认为了False\n",
    "        return observation, reward, terminated, False, info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b09a16",
   "metadata": {},
   "source": [
    "## 5. Rendering 渲染"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86a491bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Tutorial中介绍用 pygame 来实现渲染\n",
    "    \n",
    "    # 第一种针对  rgb_array ，仅仅是返还对应数据\n",
    "    # 第二种 human,则是初始化 pygame 窗口，完成动画更新，使用了render_fps\n",
    "        # 对于 human 的理解，需要学习如何搭建 pygame 窗口，以及动画更新\n",
    "    def render(self):\n",
    "        if self.render_mode == \"rgb_array\":\n",
    "            return self._render_frame()\n",
    "\n",
    "    def _render_frame(self):\n",
    "        if self.window is None and self.render_mode == \"human\":\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            self.window = pygame.display.set_mode(\n",
    "                (self.window_size, self.window_size)\n",
    "            )\n",
    "        if self.clock is None and self.render_mode == \"human\":\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        canvas = pygame.Surface((self.window_size, self.window_size))\n",
    "        canvas.fill((255, 255, 255))\n",
    "        pix_square_size = (\n",
    "            self.window_size / self.size\n",
    "        )  # The size of a single grid square in pixels\n",
    "\n",
    "        # First we draw the target\n",
    "        pygame.draw.rect(\n",
    "            canvas,\n",
    "            (255, 0, 0),\n",
    "            pygame.Rect(\n",
    "                pix_square_size * self._target_location,\n",
    "                (pix_square_size, pix_square_size),\n",
    "            ),\n",
    "        )\n",
    "        # Now we draw the agent\n",
    "        pygame.draw.circle(\n",
    "            canvas,\n",
    "            (0, 0, 255),\n",
    "            (self._agent_location + 0.5) * pix_square_size,\n",
    "            pix_square_size / 3,\n",
    "        )\n",
    "\n",
    "        # Finally, add some gridlines\n",
    "        for x in range(self.size + 1):\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                0,\n",
    "                (0, pix_square_size * x),\n",
    "                (self.window_size, pix_square_size * x),\n",
    "                width=3,\n",
    "            )\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                0,\n",
    "                (pix_square_size * x, 0),\n",
    "                (pix_square_size * x, self.window_size),\n",
    "                width=3,\n",
    "            )\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            # The following line copies our drawings from `canvas` to the visible window\n",
    "            self.window.blit(canvas, canvas.get_rect())\n",
    "            pygame.event.pump()\n",
    "            pygame.display.update()\n",
    "\n",
    "            # We need to ensure that human-rendering occurs at the predefined framerate.\n",
    "            # The following line will automatically add a delay to keep the framerate stable.\n",
    "            self.clock.tick(self.metadata[\"render_fps\"])\n",
    "        else:  # rgb_array\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd410c29",
   "metadata": {},
   "source": [
    "## 6. 关闭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5726d886",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def close(self):\n",
    "        if self.window is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gyme",
   "language": "python",
   "name": "gyme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
