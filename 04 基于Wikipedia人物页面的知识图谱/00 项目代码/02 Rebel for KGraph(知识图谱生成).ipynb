{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMhYHhfRCzYpFSfZ2s5+Ib2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wQfL8VQ5aZ_9","executionInfo":{"status":"ok","timestamp":1686672059117,"user_tz":-480,"elapsed":4501,"user":{"displayName":"SK TIAAN","userId":"01952584446737432247"}},"outputId":"92d8f162-e20d-406c-e0c8-932365f2dc92"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","/content/drive/MyDrive/2023NLPCourse/Assignment2\n"]}],"source":["# 1. Link with GoogleDrive for easy file import\n","#     The following two steps are how to link colab(fixed)\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","# Optional, one gives the path directly and then just imports it\n","#     Another, %cd to that path and then import by filename\n","\n","dir_path = '/content/drive/MyDrive/2023NLPCourse/Assignment2/'\n","\n","# The second one goes path\n","%cd /content/drive/MyDrive/2023NLPCourse/Assignment2/"]},{"cell_type":"code","source":["# 2. install package and import\n","!pip install pyvis==0.3.1\n","!pip install wikipedia\n","from pyvis import network as net\n","import networkx as nx\n","import pickle\n","import wikipedia"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5VfXxz-galTf","executionInfo":{"status":"ok","timestamp":1686672075604,"user_tz":-480,"elapsed":16491,"user":{"displayName":"SK TIAAN","userId":"01952584446737432247"}},"outputId":"94e70073-a0ad-4a4a-ca49-d0034edd66b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pyvis==0.3.1 in /usr/local/lib/python3.10/dist-packages (0.3.1)\n","Requirement already satisfied: jinja2>=2.9.6 in /usr/local/lib/python3.10/dist-packages (from pyvis==0.3.1) (3.1.2)\n","Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.10/dist-packages (from pyvis==0.3.1) (3.1)\n","Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from pyvis==0.3.1) (7.34.0)\n","Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pyvis==0.3.1) (3.0.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis==0.3.1) (67.7.2)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis==0.3.1) (0.18.2)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis==0.3.1) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis==0.3.1) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis==0.3.1) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis==0.3.1) (3.0.38)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis==0.3.1) (2.14.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis==0.3.1) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis==0.3.1) (0.1.6)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis==0.3.1) (4.8.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.9.6->pyvis==0.3.1) (2.1.2)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis==0.3.1) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis==0.3.1) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis==0.3.1) (0.2.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: wikipedia in /usr/local/lib/python3.10/dist-packages (1.4.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.11.2)\n","Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.27.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.4.1)\n"]}]},{"cell_type":"code","source":["# 3. Define the functions\n","class KB():\n","    def __init__(self):\n","        self.entities = {} # { entity_title: {...} }\n","        self.relations = [] # [ head: entity_title, type: ..., tail: entity_title,\n","          # meta: { article_url: { spans: [...] } } ]\n","        self.sources = {} # { article_url: {...} }\n","\n","    def merge_with_kb(self, kb2):\n","        for r in kb2.relations:\n","            article_url = list(r[\"meta\"].keys())[0]\n","            source_data = kb2.sources[article_url]\n","            self.add_relation(r, source_data[\"article_title\"],\n","                              source_data[\"article_publish_date\"])\n","\n","    def are_relations_equal(self, r1, r2):\n","        return all(r1[attr] == r2[attr] for attr in [\"head\", \"type\", \"tail\"])\n","\n","    def exists_relation(self, r1):\n","        return any(self.are_relations_equal(r1, r2) for r2 in self.relations)\n","\n","    def merge_relations(self, r2):\n","        r1 = [r for r in self.relations\n","              if self.are_relations_equal(r2, r)][0]\n","\n","        # if different article\n","        article_url = list(r2[\"meta\"].keys())[0]\n","        if article_url not in r1[\"meta\"]:\n","            r1[\"meta\"][article_url] = r2[\"meta\"][article_url]\n","\n","        # if existing article\n","        else:\n","            spans_to_add = [span for span in r2[\"meta\"][article_url][\"spans\"]\n","                            if span not in r1[\"meta\"][article_url][\"spans\"]]\n","            r1[\"meta\"][article_url][\"spans\"] += spans_to_add\n","\n","    def get_wikipedia_data(self, candidate_entity):\n","        try:\n","          #page = wikipedia.page(candidate_entity, auto_suggest=False)\n","          page = wikipedia.page(candidate_entity, auto_suggest=False)\n","\n","          entity_data = {\n","            \"title\": page.title,\n","            \"url\": page.url,\n","            \"summary\": page.summary\n","          }\n","          return entity_data\n","        except:\n","          entity_data = {\n","            \"title\": candidate_entity+\"*\",\n","            \"url\": \"\",\n","            \"summary\": \"\"\n","          }\n","          return entity_data\n","          #return None\n","\n","    def add_entity(self, e):\n","        self.entities[e[\"title\"]] = {k:v for k,v in e.items() if k != \"title\"}\n","\n","    def add_relation(self, r, article_title, article_publish_date):\n","        # check on wikipedia\n","        candidate_entities = [r[\"head\"], r[\"tail\"]]\n","        entities = [self.get_wikipedia_data(ent) for ent in candidate_entities]\n","\n","        # if one entity does not exist, stop\n","        if any(ent is None for ent in entities):\n","            return\n","\n","        # manage new entities\n","        for e in entities:\n","            self.add_entity(e)\n","\n","        # rename relation entities with their wikipedia titles\n","        r[\"head\"] = entities[0][\"title\"]\n","        r[\"tail\"] = entities[1][\"title\"]\n","\n","        # add source if not in kb\n","        article_url = list(r[\"meta\"].keys())[0]\n","        if article_url not in self.sources:\n","            self.sources[article_url] = {\n","                \"article_title\": article_title,\n","                \"article_publish_date\": article_publish_date\n","            }\n","\n","        # manage new relation\n","        if not self.exists_relation(r):\n","            self.relations.append(r)\n","        else:\n","            self.merge_relations(r)\n","\n","    def print(self):\n","        print(\"Entities:\")\n","        for e in self.entities.items():\n","            print(f\"  {e}\")\n","        print(\"Relations:\")\n","        for r in self.relations:\n","            print(f\"  {r}\")\n","        print(\"Sources:\")\n","        for s in self.sources.items():\n","            print(f\"  {s}\")"],"metadata":{"id":"FFVELQ6AbQbR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 4. load kb\n","kb = pickle.load(open(\"Data/Rebel.kb\", \"rb\"))"],"metadata":{"id":"FzktUaMHblFq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 5 construct graph from the saved Named Entities and Relations (in kb file)\n","net = net.Network(\n","    directed=True,\n","    width=\"1200px\",\n","    height=\"1000px\",\n","    bgcolor=\"#FFFFFF\",\n","    notebook=True,\n","    )\n","\n","# nodes\n","color_entity = \"#00FF00\"\n","for e in kb.entities:\n","    #net.add_node(e, shape=\"circle\", color=color_entity)\n","    net.add_node(e)\n","    print(\"add note\",e)\n","\n","#edges\n","for r in kb.relations:\n","    net.add_edge(r[\"head\"], r[\"tail\"], title=r[\"type\"], label=r[\"type\"])\n","    #net.add_edge(r[\"head\"], r[\"tail\"], label=r[\"type\"])\n","    print(\"add relation\",r[\"head\"],\" \",r[\"tail\"])\n","\n","net.repulsion(\n","    node_distance=230,\n","    #central_gravity=0.02,\n","    #spring_length=200,\n","    #spring_strength=0.05,\n","    damping=0.01\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QcKa-QDzb-mZ","executionInfo":{"status":"ok","timestamp":1686672075606,"user_tz":-480,"elapsed":17,"user":{"displayName":"SK TIAAN","userId":"01952584446737432247"}},"outputId":"df690bac-51b1-45bd-b128-95b4d442b591"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Local cdn resources have problems on chrome/safari when used in jupyter-notebook. \n","add note John McCarthy*\n","add note Computer scientist\n","add note Turing Award\n","add note United States National Medal of Science*\n","add note Kyoto Prize\n","add note September 4, 1927*\n","add note Stanford University\n","add note ALGOL\n","add note Cromane\n","add note County Kerry\n","add note Ireland\n","add note Republican*\n","add note Alan Turing\n","add note Princeton University\n","add note Marvin Minsky\n","add note Allen Newell\n","add note Herbert A. Simon\n","add note Donald C. Spencer\n","add note Nathaniel Rochester\n","add note Artificial intelligence\n","add note Claude Shannon\n","add note ALGOL 60\n","add note August 1959\n","add note Compatible Time-Sharing System\n","add note 1961\n","add note time-sharing systems*\n","add note BBN Time-Sharing System\n","add note Dartmouth Time Sharing System\n","add note Space fountain\n","add note 1982\n","add note The Robot and the Baby*\n","add note 2001\n","add note Short story\n","add note Social network\n","add note Internet culture\n","add note Carolyn Talcott\n","add note SRI International\n","add note October 24, 2011*\n","add relation John McCarthy*   Computer scientist\n","add relation John McCarthy*   Turing Award\n","add relation John McCarthy*   United States National Medal of Science*\n","add relation John McCarthy*   Kyoto Prize\n","add relation John McCarthy*   September 4, 1927*\n","add relation John McCarthy*   Stanford University\n","add relation ALGOL   John McCarthy*\n","add relation Cromane   County Kerry\n","add relation Cromane   Ireland\n","add relation County Kerry   Ireland\n","add relation Ireland   County Kerry\n","add relation John McCarthy*   Republican*\n","add relation Alan Turing   Princeton University\n","add relation Marvin Minsky   Princeton University\n","add relation Allen Newell   Princeton University\n","add relation Herbert A. Simon   Princeton University\n","add relation Donald C. Spencer   Princeton University\n","add relation Nathaniel Rochester   Artificial intelligence\n","add relation Claude Shannon   Artificial intelligence\n","add relation Artificial intelligence   Nathaniel Rochester\n","add relation Artificial intelligence   Claude Shannon\n","add relation ALGOL 60   August 1959\n","add relation ALGOL 60   August 1959\n","add relation ALGOL 60   ALGOL\n","add relation Compatible Time-Sharing System   1961\n","add relation Compatible Time-Sharing System   time-sharing systems*\n","add relation BBN Time-Sharing System   time-sharing systems*\n","add relation Dartmouth Time Sharing System   time-sharing systems*\n","add relation Space fountain   1982\n","add relation John McCarthy*   Stanford University\n","add relation The Robot and the Baby*   2001\n","add relation The Robot and the Baby*   Short story\n","add relation Social network   Internet culture\n","add relation Carolyn Talcott   SRI International\n","add relation John McCarthy*   October 24, 2011*\n"]}]},{"cell_type":"code","source":["net.set_edge_smooth('dynamic')\n","net.show('Data/Graph_html/Rebel.html') #saved the graph html file to the same directory as this Jupyter Notebook"],"metadata":{"id":"wEd2Ks65ckIe"},"execution_count":null,"outputs":[]}]}