{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 与 google drive 链接，导入文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3799,
     "status": "ok",
     "timestamp": 1684417443972,
     "user": {
      "displayName": "SK TIAAN",
      "userId": "01952584446737432247"
     },
     "user_tz": -480
    },
    "id": "98n8pZn2qM7H",
    "outputId": "47521eb4-407a-40fb-f638-b8e110bf96c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
      "/content/drive/MyDrive/2023NLPCourse/Assignment1/Part_B\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "dir_path = '/content/drive/MyDrive/2023NLPCourse/Assignment1/Part_B'\n",
    "\n",
    "%cd /content/drive/MyDrive/2023NLPCourse/Assignment1/Part_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17030,
     "status": "ok",
     "timestamp": 1684417460999,
     "user": {
      "displayName": "SK TIAAN",
      "userId": "01952584446737432247"
     },
     "user_tz": -480
    },
    "id": "SHgRmWs3qnhY",
    "outputId": "63d406ba-456b-481d-f5c5-f21f526ab1a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: corextopic in /usr/local/lib/python3.10/dist-packages (1.1)\n",
      "Name: scikit-learn\n",
      "Version: 1.2.2\n",
      "Summary: A set of python modules for machine learning and data mining\n",
      "Home-page: http://scikit-learn.org\n",
      "Author: \n",
      "Author-email: \n",
      "License: new BSD\n",
      "Location: /usr/local/lib/python3.10/dist-packages\n",
      "Requires: joblib, numpy, scipy, threadpoolctl\n",
      "Required-by: fastai, imbalanced-learn, librosa, lightgbm, mlxtend, qudida, sklearn-pandas, yellowbrick\n"
     ]
    }
   ],
   "source": [
    "!pip install corextopic\n",
    "!pip show scikit-learn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 处理数据以便输入 CorEx模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 52811,
     "status": "ok",
     "timestamp": 1684417513807,
     "user": {
      "displayName": "SK TIAAN",
      "userId": "01952584446737432247"
     },
     "user_tz": -480
    },
    "id": "L9ujX0hWDSKc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as ss\n",
    "import pickle\n",
    "from corextopic import corextopic as ct\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "data_anchored_corex = pd.read_excel(\"Data/preprocessed_data.xlsx\")\n",
    "train_topics = pd.read_excel(\"Data/Training_topics.xlsx\")\n",
    "df_anchored_corex = pd.DataFrame()\n",
    "\n",
    "data_words_anchored_corex = []\n",
    "for x in data_anchored_corex['Clean']:\n",
    "    data_words_anchored_corex.append(' '.join(literal_eval(x)))\n",
    "keywords = []\n",
    "for x in train_topics['Keys']:\n",
    "    keywords.append(literal_eval(x))\n",
    "\n",
    "# 该模型传入的特征是 count Vector 词频向量\n",
    "vectorizer_anchored_corex = CountVectorizer(stop_words='english', max_features=20000, binary=True)\n",
    "\n",
    "doc_word_anchored_corex = vectorizer_anchored_corex.fit_transform(data_words_anchored_corex)\n",
    "doc_word_anchored_corex = ss.csr_matrix(doc_word_anchored_corex)\n",
    "\n",
    "words = list(np.asarray(vectorizer_anchored_corex.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 训练模型，总共得到6个主题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 32764,
     "status": "ok",
     "timestamp": 1684417546565,
     "user": {
      "displayName": "SK TIAAN",
      "userId": "01952584446737432247"
     },
     "user_tz": -480
    },
    "id": "q-vJKHqzDep0"
   },
   "outputs": [],
   "source": [
    "topic_model_anchored_corex = ct.Corex(n_hidden=6, words=words, max_iter=1000, verbose=False, seed=42)\n",
    "topic_model_anchored_corex.fit(doc_word_anchored_corex, words=words, anchors = keywords, anchor_strength=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 374,
     "status": "ok",
     "timestamp": 1684417596050,
     "user": {
      "displayName": "SK TIAAN",
      "userId": "01952584446737432247"
     },
     "user_tz": -480
    },
    "id": "QJUJXHiaDyf9"
   },
   "outputs": [],
   "source": [
    "pickle.dump(topic_model_anchored_corex, open('Models/Anchored_CorEx_Train_model.model', 'wb'))\n",
    "topic_list_anchored_corex = topic_model_anchored_corex.get_topics()\n",
    "\n",
    "df_anchored_corex['Topics'] = topic_list_anchored_corex\n",
    "df_anchored_corex.to_excel('Data/Anchored_CorEx_topics.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 打印查看所有的主题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 604,
     "status": "ok",
     "timestamp": 1684417658807,
     "user": {
      "displayName": "SK TIAAN",
      "userId": "01952584446737432247"
     },
     "user_tz": -480
    },
    "id": "Tx_5OJouHMMc",
    "outputId": "fca43c7a-ab8d-4885-e8d2-5263ae7c64cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: fit, large, small, little, big, medium, loose, normally, size, run\n",
      "1: wash, shrink, dry, washing, fade, shrunk, water, cold, shrinkage, hold\n",
      "2: fit, great, good, quality, nice, perfect, price, shirt, product, love\n",
      "3: material, soft, fabric, durable, rough, snug, athletic, sew, comfortable, feel\n",
      "4: color, look, long, sleeve, short, pocket, length, pretty, old, shape\n",
      "5: buy, quality, purchase, value, cheap, money, poor, expensive, seller, high\n"
     ]
    }
   ],
   "source": [
    "anchored_corex_topics = topic_model_anchored_corex.get_topics()\n",
    "for n,topic in enumerate(anchored_corex_topics):\n",
    "    topic_words,_,_ = zip(*topic)\n",
    "    print('{}: '.format(n) + ', '.join(topic_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 使用抽取好的主题为每个数据标记主题，结果保存在 CorEx_labelled_aspect.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 57106,
     "status": "ok",
     "timestamp": 1684417820788,
     "user": {
      "displayName": "SK TIAAN",
      "userId": "01952584446737432247"
     },
     "user_tz": -480
    },
    "id": "89DPwp1-HbiB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from ast import literal_eval\n",
    "\n",
    "data = pd.read_excel(\"Data/preprocessed_data.xlsx\")\n",
    "aspect_list = [[],[],[],[],[],[]]\n",
    "words_set = []\n",
    "for x in data['Clean']:\n",
    "    words_set.append(set(literal_eval(x)))\n",
    "\n",
    "model = pickle.load(open(\"Models/Anchored_CorEx_Train_model.model\", 'rb'))\n",
    "topic_list = []\n",
    "for i, topic_words in enumerate(model.get_topics()):\n",
    "    topic_list.append(set([words[0] for words in topic_words if words[1] > 0]))\n",
    "\n",
    "for words in words_set:\n",
    "    for i,topic_words in enumerate(topic_list):\n",
    "        if (words & topic_words):\n",
    "            aspect_list[i].append(1)\n",
    "        else :\n",
    "            aspect_list[i].append(0)\n",
    "for i in range(6):\n",
    "    data['Topic ' + str(i)] = aspect_list[i]\n",
    "data.to_excel('Data/CorEx_labelled_aspect.xlsx')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyORaZQHDbHE1U3O0nnEFoS0",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
