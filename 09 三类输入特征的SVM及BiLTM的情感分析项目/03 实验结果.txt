整个项目代码运行在 google Colab 中

对于4类模型 SVM_CountVectorizer，SVM_TfidfVectorizer，CBOW_BiLSTM_model，Skipgram_BiLSTM_model
	四者最终的性能表现差异相近，测试集上均为 0.89
BiLSTM 的模型参大于 SVM

====

不同点，主要体现在两个模型的训练时长
	SVM两个模型训练时间为接近 1小时
		并且 CountVectorizer，TfidfVectorizer 两者花费的时间已经达到了 30分钟

	对于 BiLSTM 模型，训练时长主要花费在 Word2Vec模型训练
		但对于 BiLSTM 模型，仅花费了 几分钟

====

发现：
	在该实验中有尝试 Embedding 层不导入 花费时间训练的 Word2Vec 模型参数
		而是直接在 BiLSTM 模型中使用 raw Embedding 层，跟随情感分析模型训练而调整
	此改动不仅最终效果达到近 0.91，还大大节省了项目训练时间


